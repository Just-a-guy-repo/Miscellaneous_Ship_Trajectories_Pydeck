{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34426d3b-9ecd-483a-8bb4-dd8b753e13ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "dir = Path('/Users/kamma/Downloads')\n",
    "base_fname = 'AIS_2022_01_01'\n",
    "\n",
    "pq_fname = (dir / base_fname).with_suffix('.parquet')\n",
    "if pq_fname.exists():\n",
    "    print(\"Loading parquet\")\n",
    "    df = pd.read_parquet(pq_fname)\n",
    "else:\n",
    "    if (fname := (dir / base_fname).with_suffix('.csv.gz')).exists():\n",
    "        print(\"Loading csv.gz\")\n",
    "        df = pd.read_csv(fname)\n",
    "    elif (fname := (dir / base_fname).with_suffix('.zip')).exists():\n",
    "        print(\"Loading zip\")\n",
    "        df = pd.read_csv(fname)\n",
    "    df = df.assign(BaseDateTime=pd.to_datetime(df.BaseDateTime))\n",
    "    df.to_parquet(pq_fname)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc84dbc8-be1f-4f4b-81bc-d43763696587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)\n",
    "def haversine(lon1, lat1, lon2, lat2, earth_radius=6371.009):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.\n",
    "\n",
    "    \"\"\"\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat1 = np.radians(lat1)\n",
    "    lon2 = np.radians(lon2)\n",
    "    lat2 = np.radians(lat2)\n",
    "    \n",
    "    # lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = earth_radius * c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04da7e4-d5ec-4218-88d4-811661907377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_running_intervals(vdf, speed_threshold, window_size=5):\n",
    "    low_speed = vdf[\"speed\"] < speed_threshold\n",
    "    count_speed = low_speed.rolling(window_size, center=True).sum().fillna(method='ffill').fillna(method='bfill')\n",
    "    zeros = count_speed[count_speed < 1].index.to_series()\n",
    "    fives = count_speed[count_speed > window_size-1].index.to_series()\n",
    "    zeros.iloc[:] = False\n",
    "    fives.iloc[:] = True\n",
    "    mix = pd.concat([zeros, fives]).sort_index()\n",
    "    mismatch = (mix != mix.shift().fillna(mix))\n",
    "    if len(mismatch) > 1:\n",
    "        mismatch_back = mismatch.shift(-1).fillna(False)\n",
    "        back_matches = mix[mismatch_back & mix].index\n",
    "        forward_matches = mix[mismatch & mix].index\n",
    "    else:\n",
    "        back_matches = pd.Series(dtype='int').index\n",
    "        forward_matches = pd.Series(dtype='int').index\n",
    "\n",
    "    extras = []\n",
    "    if len(mix[mismatch]) == 0:\n",
    "        if len(zeros) > len(fives):\n",
    "            extras.append(low_speed.iloc[:1].index[0])\n",
    "            extras.append(low_speed.iloc[-1:].index[0])\n",
    "    else:\n",
    "        if mix[mismatch].iloc[0]:\n",
    "            # False -> True so include 0\n",
    "            extras.append(low_speed.iloc[:1].index[0])\n",
    "        if not mix[mismatch].iloc[-1]:\n",
    "            # True -> False so include -1\n",
    "            extras.append(low_speed.iloc[-1:].index[0])\n",
    "    if len(extras) > 0:\n",
    "        s = pd.concat([pd.Series(extras, extras),back_matches.to_series() + (window_size-1)//2,\n",
    "                forward_matches.to_series() - (window_size+1)//2]).sort_index()\n",
    "    else:\n",
    "        s = pd.concat([back_matches.to_series() + (window_size-1)//2,\n",
    "                forward_matches.to_series() - (window_size+1)//2]).sort_index()\n",
    "    intervals = s.values.reshape((len(s)//2,2))\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765a65f6-f004-4235-9c7b-e1d1911bea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = df.sort_values(['MMSI','BaseDateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b0420-d9ee-4fe2-a52d-c5100e42fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "LAT_COL = \"LAT\"\n",
    "LON_COL = \"LON\"\n",
    "SPEED_MIN = 0.026 / 60.0 # 26 m/min ~ 1 mph, 0.015 / 60.0 # 15 meters/minute\n",
    "SPEED_MAX = 8 / 60.0 # 8 km/min ~ 300 mph\n",
    "TIME_THRESHOLD = pd.Timedelta(minutes=120)\n",
    "WINDOW_SIZE = 5\n",
    "\n",
    "cur_id = 0\n",
    "subtrajectories = []\n",
    "for mmsi, vdf in tqdm(full_df.groupby('MMSI')):\n",
    "    vdf = (vdf.drop_duplicates(subset=\"BaseDateTime\", keep=\"first\")\n",
    "        .reset_index(drop=True)\n",
    "        .assign(\n",
    "            dist=lambda df: haversine(df[LON_COL].values, df[LAT_COL].values, \n",
    "                            df[LON_COL].shift(1).values, df[LAT_COL].shift(1).values),\n",
    "            diff_dt=lambda df: df.BaseDateTime.diff(),\n",
    "            speed=lambda df: df.dist / df.diff_dt.dt.total_seconds()\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # gaps\n",
    "    gaps = (vdf[\"diff_dt\"] > TIME_THRESHOLD) | (vdf[\"speed\"] > SPEED_MAX)\n",
    "    last_idx = vdf.iloc[-1:].index[0]+1\n",
    "    gaps_idx = pd.concat([pd.Series([0],[0]), vdf[gaps].index.to_series(), pd.Series([last_idx],[last_idx])])\n",
    "    gaps_intervals = pd.DataFrame([gaps_idx, gaps_idx.shift(-1) - 1]).T.iloc[:-1].astype(int)\n",
    "\n",
    "    for (start, end) in gaps_intervals.itertuples(index=False):\n",
    "        svdf = vdf.loc[start:end]\n",
    "        # if mmsi == 270995:\n",
    "        #     display(svdf.head(5), svdf.tail(5))\n",
    "        rints = get_running_intervals(svdf, SPEED_MIN, WINDOW_SIZE)\n",
    "        # if mmsi == 270995:\n",
    "        #     display(rints)\n",
    "        for row in rints:\n",
    "            rvdf = svdf.loc[row[0]:row[1]].assign(SubtrajID=cur_id)\n",
    "            # rvdf['SubtrajID'] = cur_id\n",
    "            cur_id += 1\n",
    "            subtrajectories.append(rvdf)\n",
    "            # print(\"GOT RINTS\", len(subtrajectories))\n",
    "len(subtrajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f20389-a001-46d3-a23b-e15bcf5ba878",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtrajs = pd.concat(subtrajectories)\n",
    "subtrajs[['MMSI','BaseDateTime',LAT_COL,LON_COL,'SOG','COG','Heading','SubtrajID']].to_parquet((dir / (base_fname + '-moving')).with_suffix('.parquet'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152bff11-a91b-4d40-ae96-8c93f8ebd3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "dir = Path('/Users/kamma/Downloads')\n",
    "base_fname = 'AIS_2022_01_01'\n",
    "\n",
    "moving_fname = (dir / (base_fname + '-moving')).with_suffix('.parquet')\n",
    "\n",
    "if not moving_fname.exists():\n",
    "    raise ValueError(f'\"{moving_fname}\" not found. Run ais-split-voyages.ipynb')\n",
    "trajs = pd.read_parquet(moving_fname)\n",
    "trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1f171b-2841-46ea-ac8a-ef5a0ef2eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_df = trajs.groupby('SubtrajID')[['LON','LAT']].apply(lambda df: [df.values.astype('float32')]).str[0].rename(\"path\").to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d4cacf-01c0-4bc2-bd58-7384d480dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydeck as pdk\n",
    "\n",
    "# def hex_to_rgb(h):\n",
    "#     h = h.lstrip(\"#\")\n",
    "#     return tuple(int(h[i : i + 2], 16) for i in (0, 2, 4))\n",
    "\n",
    "# final_viz_redu[\"color\"] = final_viz_redu[\"color\"].apply(hex_to_rgb)\n",
    "\n",
    "view_state = pdk.ViewState(longitude=-82.77474, latitude=28.08771, zoom=6)\n",
    "\n",
    "layer = pdk.Layer(\n",
    "    type=\"PathLayer\",\n",
    "    data=vis_df,\n",
    "    pickable=True,\n",
    "    # get_color=\"color\",\n",
    "    get_color=[255,0,0,255],\n",
    "    width_scale=20,\n",
    "    width_min_pixels=2,\n",
    "    get_path=\"path\",\n",
    "    get_width=5,\n",
    "    use_binary_transport=False\n",
    ")\n",
    "\n",
    "r = pdk.Deck(layers=[layer], initial_view_state=view_state) #, tooltip={\"text\": \"{MMSI}\"})\n",
    "r.to_html()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
